{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"10. Softmax and Cross Entropy.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNNkSYICApGc0EmhQaNNKcd"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"qhNCVxuEz2dJ","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"F-2vs5tV1UH3","colab_type":"text"},"source":["softmax"]},{"cell_type":"code","metadata":{"id":"w_0YQ3av0IXA","colab_type":"code","outputId":"da29e0e9-2918-4a77-90c7-c94a82276641","executionInfo":{"status":"ok","timestamp":1587306317489,"user_tz":-540,"elapsed":568,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["def softmax(x):\n","    return np.exp(x) / np.sum(np.exp(x), axis=0)\n","\n","x = np.array([2.0, 1.0, 0.1])\n","output = softmax(x)\n","print(output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["[0.65900114 0.24243297 0.09856589]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ygctXD8T0IZ1","colab_type":"code","outputId":"049dc68b-5272-403a-dbb0-52df7d76bca5","executionInfo":{"status":"ok","timestamp":1587306346570,"user_tz":-540,"elapsed":570,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["x = torch.tensor([2.0, 1.0, 0.1])\n","output = torch.softmax(x, dim=0)\n","print(output)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([0.6590, 0.2424, 0.0986])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"z33JhB8g0IcQ","colab_type":"text"},"source":["cross entropy"]},{"cell_type":"code","metadata":{"id":"EPqXXXEw0Ieb","colab_type":"code","outputId":"86180672-e840-4d0d-883b-aa2f6d376862","executionInfo":{"status":"ok","timestamp":1587306587618,"user_tz":-540,"elapsed":576,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":52}},"source":["def ce(actual, predicted):\n","    loss = -np.sum(actual*np.log(predicted))\n","    return loss\n","\n","Y = np.array([1,0,0]) # one hot encoding label\n","\n","Y_pred_good = np.array([0.7, 0.2, 0.1]) # softmax를 지난 뒤로 가정\n","Y_pred_bad = np.array([0.1, 0.3, 0.6])\n","\n","l1 = ce(Y, Y_pred_good)\n","l2 = ce(Y, Y_pred_bad)\n","print(f'l1 : {l1:.4f}')\n","print(f'l2 : {l2:.4f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["l1 : 0.3567\n","l2 : 2.3026\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ydd--VFm0Igz","colab_type":"code","outputId":"6e8e87d4-b28b-4f8b-9f1a-a7f3695babb2","executionInfo":{"status":"ok","timestamp":1587308483980,"user_tz":-540,"elapsed":845,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":105}},"source":["loss = nn.CrossEntropyLoss()\n","# nn.CrossEntropyLoss 에 이미 softmax가 들어가 있다\n","# 중복사용하지 않게 주의하자!\n","# label에 대해 one hot encoding 하면 안된다\n","\n","Y = torch.tensor([2,0,1]) # 3 sample\n","\n","# nsamples * nclass = 3 * 3\n","Y_pred_good = torch.tensor([[0.1, 1.0, 2.1],[2.0, 1.0, 0.1],[1.0, 2.0, 0.1]])\n","print(Y_pred_good.shape)\n","Y_pred_bad = torch.tensor([[0.5, 2.0, 0.3],[2.0, 1.0, 0.1],[2.0, 1.0, 0.1]])\n","\n","l1 = loss(Y_pred_good, Y)\n","l1 = loss(Y_pred_bad, Y)\n","print(l1.item())\n","print(l2.item())\n","\n","_, prediction1 = torch.max(Y_pred_good, 1)\n","_, prediction2 = torch.max(Y_pred_bad, 1)\n","print(prediction1) # 예측 잘함\n","print(prediction2) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([3, 3])\n","1.2915587425231934\n","2.3025850929940455\n","tensor([2, 0, 1])\n","tensor([1, 0, 0])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"88BVCyXm8Res","colab_type":"text"},"source":["class로 구현"]},{"cell_type":"code","metadata":{"id":"_TYSbZvC3Tgr","colab_type":"code","colab":{}},"source":["# multiclass\n","class NN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_class):\n","        super().__init__()\n","        self.Linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.Linear2 = nn.Linear(hidden_size, num_class)\n","\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        return out\n","\n","model = NN(input_size=28*28, hidden_size=5,num_class=5)\n","criterion = nn.CrossEntropyLoss()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9c3OWyiU6U4K","colab_type":"code","colab":{}},"source":["# binary class\n","class NN(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super().__init__()\n","        self.Linear1 = nn.Linear(input_size, hidden_size)\n","        self.relu = nn.ReLU()\n","        self.Linear2 = nn.Linear(hidden_size, 1)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        out = self.linear1(x)\n","        out = self.relu(out)\n","        out = self.linear2(out)\n","        out = self.sigmoid(out) # binary의 경우 마지막에 sigmoid layer\n","        return out\n","\n","model = NN(input_size=28*28, hidden_size=5)\n","criterion = nn.BCELoss() # Binary Cross Entropy Loss"],"execution_count":0,"outputs":[]}]}