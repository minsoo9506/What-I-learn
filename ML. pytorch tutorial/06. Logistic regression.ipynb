{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"06. Logistic regression.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMpQfuBoqx/qhuo7fygA9/v"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"pn60GpO1xmjD","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import numpy as np\n","from sklearn import datasets\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_iAg3HXN3pwF","colab_type":"code","colab":{}},"source":["# 0. prepare data\n","bc = datasets.load_breast_cancer()\n","X, y = bc.data, bc.target\n","\n","n_samples, n_features = X.shape\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n","\n","## scale\n","sc = StandardScaler()\n","X_train = sc.fit_transform(X_train)\n","X_test = sc.transform(X_test)\n","\n","X_train = torch.from_numpy(X_train.astype(np.float32))\n","X_test = torch.from_numpy(X_test.astype(np.float32))\n","y_train = torch.from_numpy(y_train.astype(np.float32))\n","y_test = torch.from_numpy(y_test.astype(np.float32))\n","\n","y_train = y_train.view(y_train.shape[0],1)\n","y_test = y_test.view(y_test.shape[0],1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bPda-DDI4-uU","colab_type":"code","colab":{}},"source":["# 1. model\n","class LogisticRegression(nn.Module):\n","\n","    def __init__(self, n_input_features):\n","        super().__init__()\n","        self.linear = nn.Linear(n_input_features, 1)\n","\n","    def forward(self, x):\n","        y_predict = torch.sigmoid(self.linear(x))\n","        return y_predict\n","\n","model = LogisticRegression(n_features)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VwiYpZp44-xO","colab_type":"code","colab":{}},"source":["# 2. loss and optimizer\n","learning_rate = 0.01\n","criterion = nn.BCELoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"spaoKRvu5Dc_","colab_type":"code","outputId":"21f469b2-f647-4e10-8a54-165b609ded08","executionInfo":{"status":"ok","timestamp":1587140359028,"user_tz":-540,"elapsed":816,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":210}},"source":["# 3. training loss\n","num_epochs = 100\n","for epoch in range(num_epochs):\n","    # forward and loss\n","    y_predicted = model(X_train)\n","    loss = criterion(y_predicted, y_train)\n","    # backward\n","    loss.backward()\n","    # optim\n","    optimizer.step()\n","    # zero_gradient\n","    optimizer.zero_grad()\n","\n","    if epoch % 10 == 1:\n","        print(f'epoch : {epoch}, loss = {loss.item():.4f}')\n","# test\n","with torch.no_grad() :\n","    y_predicted = model(X_test)\n","    y_predicted_cls = y_predicted.round() # classification이니까 0.5이상은 1 나머지는 0\n","    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n","    print(f'accuracy = {acc:.4f}')"],"execution_count":0,"outputs":[{"output_type":"stream","text":["epoch : 1, loss = 0.0913\n","epoch : 11, loss = 0.0911\n","epoch : 21, loss = 0.0909\n","epoch : 31, loss = 0.0907\n","epoch : 41, loss = 0.0906\n","epoch : 51, loss = 0.0904\n","epoch : 61, loss = 0.0902\n","epoch : 71, loss = 0.0901\n","epoch : 81, loss = 0.0899\n","epoch : 91, loss = 0.0897\n","accuracy = 0.9650\n"],"name":"stdout"}]}]}