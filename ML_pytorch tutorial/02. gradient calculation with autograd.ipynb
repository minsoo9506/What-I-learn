{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"02. gradient calculation with autograd.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyO0Zv/hOVR+HqLHvO0OMR96"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RUKMfBsBwSNu","colab_type":"code","colab":{}},"source":["import torch"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eWbdRM7nCKeB","colab_type":"text"},"source":["requires_grad"]},{"cell_type":"code","metadata":{"id":"TOvSXbBQ2qQZ","colab_type":"code","outputId":"fbac27dd-bc36-411d-c58b-0c9edd572cc9","executionInfo":{"status":"ok","timestamp":1586855126467,"user_tz":-540,"elapsed":666,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":110}},"source":["x = torch.randn(3, requires_grad=True)\n","print(x)\n","print(x.grad)\n","\n","y = x+2\n","print(y)\n","\n","z = y*y*2\n","print(z)\n","\n","z = z.mean() # 스칼라\n","print(z)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ 0.7367, -0.1329,  0.7211], requires_grad=True)\n","None\n","tensor([2.7366, 1.8671, 2.7211], grad_fn=<AddBackward0>)\n","tensor([14.9785,  6.9724, 14.8093], grad_fn=<MulBackward0>)\n","tensor(12.2534, grad_fn=<MeanBackward0>)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZPfKL5Mn3Rx9","colab_type":"code","outputId":"eea66f5a-8b03-41d9-db61-67477b4e4bee","executionInfo":{"status":"ok","timestamp":1586854001273,"user_tz":-540,"elapsed":514,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["z.backward() # dz/dx\n","# requires_grad=True 안하면 backward() 에러 발생\n","# backward()시에 마지막이 스칼라가 되어야한다\n","\n","print(x.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([2.9479, 3.8577, 3.1249])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"XZgqW1XF3ngF","colab_type":"code","outputId":"5c00d9ae-226c-4121-eb22-8e96d0661a3e","executionInfo":{"status":"ok","timestamp":1586854298219,"user_tz":-540,"elapsed":620,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":36}},"source":["# 이번에는 z가 스칼라가 아닌 경우\n","x = torch.randn(3, requires_grad=True)\n","y = x+2\n","z = y*y*2\n","\n","v = torch.tensor([0.1, 1.0, 0.001])\n","z.backward(v) # v가 없으면 에러발생\n","print(x.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([1.3078e+00, 5.8424e+00, 4.9726e-03])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"C6__DPPcCP44","colab_type":"text"},"source":["- x.requires_grad_(False)\n","- x.detach()\n","- with torch.no_grad():"]},{"cell_type":"code","metadata":{"id":"D9jekmo34uon","colab_type":"code","outputId":"339c40aa-95d0-490a-97d9-7d083a2dea5b","executionInfo":{"status":"ok","timestamp":1586854752776,"user_tz":-540,"elapsed":579,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":91}},"source":["# stop gradient 방법\n","# 따라서 prediction 할 때 사용\n","\n","# x.requires_grad_(False)\n","# x.detach()\n","# with torch.no_grad():\n","\n","x = torch.randn(3, requires_grad=True)\n","print(x)\n","\n","x = torch.randn(3, requires_grad=True)\n","x.requires_grad_(False)\n","print(x)\n","\n","x = torch.randn(3, requires_grad=True)\n","x.detach_()\n","print(x)\n","\n","x = torch.randn(3, requires_grad=True)\n","with torch.no_grad():\n","    y = x + 2\n","    print(y)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([ 1.0162,  0.5918, -0.4185], requires_grad=True)\n","tensor([ 1.9918, -0.2379,  0.9113])\n","tensor([-0.2051,  0.0445, -0.6908])\n","tensor([1.5224, 3.0651, 2.9491])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ckJx-s-c5dXC","colab_type":"code","outputId":"d36533ca-3074-4af2-e776-1e1e32e8df31","executionInfo":{"status":"ok","timestamp":1586854647461,"user_tz":-540,"elapsed":663,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["# backward는 누적된다. 따라서 정확한 gradient 계산을 위해서는\n","# 지워야 한다.\n","\n","weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    model_output = (weights*3).sum()\n","\n","    model_output.backward()\n","\n","    print(weights.grad)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([3., 3., 3., 3.])\n","tensor([6., 6., 6., 6.])\n","tensor([9., 9., 9., 9.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"huHU3ST16Ald","colab_type":"code","outputId":"fd2146f0-2da9-408a-c26c-139877844c05","executionInfo":{"status":"ok","timestamp":1586854810122,"user_tz":-540,"elapsed":599,"user":{"displayName":"송민수","photoUrl":"","userId":"01995057677702855947"}},"colab":{"base_uri":"https://localhost:8080/","height":73}},"source":["weights = torch.ones(4, requires_grad=True)\n","\n","for epoch in range(3):\n","    model_output = (weights*3).sum()\n","\n","    model_output.backward()\n","\n","    print(weights.grad)\n","\n","    weights.grad.zero_()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n","tensor([3., 3., 3., 3.])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LCRZn5-f6oAG","colab_type":"code","colab":{}},"source":["# optimizer\n","# 나중에 model train시에는 이렇게 backprop한다.\n","weights = torch.ones(4, requires_grad=True)\n","\n","optimizer = torch.optim.SGD(weights, lr=0.01)\n","optimizer.step()\n","optimizer.zero_grad()"],"execution_count":0,"outputs":[]}]}